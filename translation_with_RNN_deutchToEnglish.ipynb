{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hiddouche/NLP/blob/master/translation_with_RNN_deutchToEnglish.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U7ZErKkPkW3v"
   },
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JpARbAlMkW3y"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Bidirectional, RepeatVector, TimeDistributed\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RrlXAEWYkW37"
   },
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sFmwvRQgkW38"
   },
   "source": [
    "Our data is a text file of English-German sentence pairs. First we will read the file using the function defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bE1vCEu1kW3-"
   },
   "outputs": [],
   "source": [
    "# function to read raw text file\n",
    "def read_text(filename):\n",
    "    # open the file\n",
    "    file = open(filename, mode='rt', encoding='utf-8')\n",
    "    # read all text\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fvGdgAh2kW4G"
   },
   "source": [
    "Now let's define a function to split the text into English-German pairs separated by '\\n' and then split these pairs into English sentences and German sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AsX8hvR7kW4H"
   },
   "outputs": [],
   "source": [
    "# split a text into sentences\n",
    "def to_lines(text):\n",
    "    sents = text.strip().split('\\n')\n",
    "    sents = [i.split('\\t') for i in sents]\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SxIuWsbOr0lN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LTvxbxE3mcmw"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "data_path = os.path.join(\"datasets\", \"\")\n",
    "filename = \"deu.txt\"\n",
    "URL = \"https://docs.google.com/uc?export=download&id=1LYw_wl5ftE4ejhFPFpfar4lt1HvNKZgN\"\n",
    " \n",
    "os.makedirs(data_path, exist_ok=True)\n",
    " \n",
    "print(\"Downloading deu.txt\")\n",
    "\n",
    "urllib.request.urlretrieve(URL, data_path + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Vxqjm6Isjpq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "66ztfb7RkW4O"
   },
   "source": [
    "__Download the data from [here.](http://www.manythings.org/anki/deu-eng.zip)__ and extract \"deu.txt\" in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfHkFI9GkW4R"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " \n",
    "data = read_text(os.path.join(\"datasets\", \"\")+\"deu.txt\")\n",
    "deu_eng = to_lines(data)\n",
    "deu_eng = array(deu_eng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJ7iHFvHkW4X"
   },
   "source": [
    "The actual data contains over 150,000 sentence-pairs. However, we will use the first 50,000 sentence pairs only to reduce the training time of the model. You can change this number as per you system computation power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xi-eUL3lkW4Y"
   },
   "outputs": [],
   "source": [
    "deu_eng = deu_eng[:50000,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-ZOrDO8kW4e"
   },
   "source": [
    "### Text Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rbaq_W4nkW4g"
   },
   "source": [
    "#### Text Cleaning\n",
    "\n",
    "Let's take a look at our data, then we will decide which pre-processing steps to adopt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7bizcIVkW4h",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sK7CUIoXkW4z"
   },
   "source": [
    "We will get rid of the punctuation marks, and then convert the text to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LR1qyfRhkW40"
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "deu_eng[:,0] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,0]]\n",
    "deu_eng[:,1] = [s.translate(str.maketrans('', '', string.punctuation)) for s in deu_eng[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZfAluSdLkW46"
   },
   "outputs": [],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LjNT2J0okW5B",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert to lowercase\n",
    "for i in range(len(deu_eng)):\n",
    "    deu_eng[i,0] = deu_eng[i,0].lower()\n",
    "    \n",
    "    deu_eng[i,1] = deu_eng[i,1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6mInmVwJkW5H"
   },
   "outputs": [],
   "source": [
    "deu_eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9sYTCPVmkW5M"
   },
   "source": [
    "#### Text to Sequence Conversion\n",
    "\n",
    "To feed our data in a Seq2Seq model, we will have to convert both the input and the output sentences into integer sequences of fixed length. Before that, let's visualise the length of the sentences. We will capture the lengths of all the sentences in two separate lists for English and German, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVdGdCg5kW5N"
   },
   "outputs": [],
   "source": [
    "# empty lists\n",
    "eng_l = []\n",
    "deu_l = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in deu_eng[:,0]:\n",
    "    eng_l.append(len(i.split()))\n",
    "\n",
    "for i in deu_eng[:,1]:\n",
    "    deu_l.append(len(i.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgr0H6tPkW5T"
   },
   "outputs": [],
   "source": [
    "length_df = pd.DataFrame({'eng':eng_l, 'deu':deu_l})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Zn_Ja6_kW5a"
   },
   "outputs": [],
   "source": [
    "length_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnfnW7ggkW5k"
   },
   "outputs": [],
   "source": [
    "length_df.hist(bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YIibcmbkkW5r"
   },
   "source": [
    "The maximum length of the German sentences is 11 and that of the English phrases is 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lk5aAubHkW5s"
   },
   "source": [
    "Let's vectorize our text data by using Keras's Tokenizer() class. It will turn our sentences into sequences of integers. Then we will pad those sequences with zeros to make all the sequences of same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1wzkfAjEkW5t"
   },
   "outputs": [],
   "source": [
    "# function to build a tokenizer\n",
    "def tokenization(lines):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(lines)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1qIIEq5skW53"
   },
   "outputs": [],
   "source": [
    "# prepare english tokenizer\n",
    "eng_tokenizer = tokenization(deu_eng[:, 0])\n",
    "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
    "\n",
    "eng_length = 8\n",
    "print('English Vocabulary Size: %d' % eng_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JwhDF-mikW6A"
   },
   "outputs": [],
   "source": [
    "# prepare Deutch tokenizer\n",
    "deu_tokenizer = tokenization(deu_eng[:, 1])\n",
    "deu_vocab_size = len(deu_tokenizer.word_index) + 1\n",
    "\n",
    "deu_length = 8\n",
    "print('Deutch Vocabulary Size: %d' % deu_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nrRk5kDgkW6H"
   },
   "source": [
    "Given below is a function to prepare the sequences. It will also perform sequence padding to a maximum sentence length as mentioned above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ssUF7bi6kW6I"
   },
   "outputs": [],
   "source": [
    "# encode and pad sequences\n",
    "def encode_sequences(tokenizer, length, lines):\n",
    "    # integer encode sequences\n",
    "    seq = tokenizer.texts_to_sequences(lines)\n",
    "    print(\"-----------------------\")\n",
    "    print(seq)\n",
    "    print(\"-----------------------\")\n",
    "    # pad sequences with 0 values\n",
    "    seq = pad_sequences(seq, maxlen=length, padding='post')\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BySM-UockW6T"
   },
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8h2mdSTTkW6V"
   },
   "source": [
    "We will now split the data into train and test set for model training and evaluation, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HzsfGUHFkW6W"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(deu_eng, test_size=0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "twX-1sirkW6b"
   },
   "source": [
    "It's time to encode the sentences. We will encode German sentences as the input sequences and English sentences as the target sequences. It will be done for both train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NzZrBeP1kW6c"
   },
   "outputs": [],
   "source": [
    "# prepare training data\n",
    "trainX = encode_sequences(deu_tokenizer, deu_length, train[:, 1])\n",
    "trainY = encode_sequences(eng_tokenizer, eng_length, train[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tNrNTYrJkW6i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M-eyUsrokW6p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Ie5Waq-kW6u"
   },
   "outputs": [],
   "source": [
    "# prepare validation data\n",
    "testX = encode_sequences(deu_tokenizer, deu_length, test[:, 1])\n",
    "testY = encode_sequences(eng_tokenizer, eng_length, test[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54uTI5zVkW60"
   },
   "source": [
    "Now comes the exciting part! Let us define our Seq2Seq model architecture. We are using an Embedding layer and an LSTM layer as our encoder and another LSTM layer followed by a Dense layer as the decoder.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aE1rp_uAkW61"
   },
   "outputs": [],
   "source": [
    "# build NMT model\n",
    "def build_model(in_vocab, out_vocab, in_timesteps, out_timesteps, units):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(in_vocab, units, input_length=in_timesteps, mask_zero=True))\n",
    "    model.add(LSTM(units))\n",
    "    model.add(RepeatVector(out_timesteps))\n",
    "    model.add(LSTM(units, return_sequences=True))\n",
    "    model.add(Dense(out_vocab, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1X8hf3KkW66"
   },
   "source": [
    "We are using RMSprop optimizer in this model as it is usually a good choice for recurrent neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7cSFA231kW67"
   },
   "outputs": [],
   "source": [
    "model = build_model(deu_vocab_size, eng_vocab_size, deu_length, eng_length, 512)\n",
    "rms = optimizers.RMSprop(lr=0.001)\n",
    "model.compile(optimizer=rms, loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_zod-ntZkW7A"
   },
   "source": [
    "Please note that we have used __'sparse_categorical_crossentropy'__ as the loss function because it allows us to use the target sequence as it is instead of one hot encoded format. One hot encoding the target sequences with such a huge vocabulary might consume our system's entire memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VOPeCg9HkW7A"
   },
   "source": [
    "It seems we are all set to start training our model. We will train it for 30 epochs and with a batch size of 512. You may change and play these hyperparameters. We will also be using __ModelCheckpoint()__ to save the best model with lowest validation loss. I personally prefer this method over early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "t5B3xRyvkW7B",
    "outputId": "d9fa086c-9c64-4b91-a5e4-a7271c3c9cdf",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "Epoch 1/30\n",
      "22016/32000 [===================>..........] - ETA: 1:39 - loss: 0.3888"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-ac11aca639b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           callbacks=[checkpoint], verbose=1)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filename = 'model.h1.11_07_2020'\n",
    "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "history = model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1), \n",
    "          epochs=30, batch_size=512, \n",
    "          validation_split = 0.2,\n",
    "          callbacks=[checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2fFqL4_kW7H"
   },
   "source": [
    "Let's compare the training loss and the validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "colab_type": "code",
    "id": "O3TQpeGLkW7I",
    "outputId": "0870c3f3-3e69-4609-e6bc-969ac22cad0a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['train','validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z1MEsRIEkW7N"
   },
   "source": [
    "### Make Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K7Kk2bEtkW7O"
   },
   "source": [
    "Let's load the saved model to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "-BqTA3_SkW7Q",
    "outputId": "def88e55-08bf-4aa8-984c-ed8d387455cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    }
   ],
   "source": [
    "model = load_model('model.h1.11_07_2020')\n",
    "preds = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2yLq-oO9kW7V"
   },
   "outputs": [],
   "source": [
    "def get_word(n, tokenizer):\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == n:\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gYkBepFMkW7Z"
   },
   "outputs": [],
   "source": [
    "# convert predictions into text (English)\n",
    "preds_text = []\n",
    "for i in preds:\n",
    "    temp = []\n",
    "    for j in range(len(i)):\n",
    "        t = get_word(i[j], eng_tokenizer)\n",
    "        if j > 0:\n",
    "            if (t == get_word(i[j-1], eng_tokenizer)) or (t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)\n",
    "             \n",
    "        else:\n",
    "            if(t == None):\n",
    "                temp.append('')\n",
    "            else:\n",
    "                temp.append(t)            \n",
    "        \n",
    "    preds_text.append(' '.join(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Coy-dIXwkW7e"
   },
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({'actual' : test[:,0], 'predicted' : preds_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DVc090BokW7j"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "OGsRIK5kkW7p",
    "outputId": "d893e619-ac33-4447-c025-9eb53ea18d88"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it cannot last long</td>\n",
       "      <td>it cant be long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>am i right</td>\n",
       "      <td>i am right</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>guess who i am</td>\n",
       "      <td>what am i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>were in town</td>\n",
       "      <td>were in the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tom runs the fastest</td>\n",
       "      <td>tom can making stamps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i will vouch for him</td>\n",
       "      <td>ill get him</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>can i spend the night</td>\n",
       "      <td>can i order here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>please write it down</td>\n",
       "      <td>please that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the water is hot</td>\n",
       "      <td>the water is hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>they always complain</td>\n",
       "      <td>theyre always jealous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>lock the door</td>\n",
       "      <td>close the door</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>its great</td>\n",
       "      <td>its great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>i hope we win</td>\n",
       "      <td>i hope you win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>i can do more</td>\n",
       "      <td>i can explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>anyone can do it</td>\n",
       "      <td>anybody can do</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   actual                   predicted\n",
       "0     it cannot last long         it cant be long    \n",
       "1              am i right             i am right     \n",
       "2          guess who i am              what am i     \n",
       "3            were in town            were in the     \n",
       "4    tom runs the fastest   tom can making stamps    \n",
       "5    i will vouch for him            ill get him     \n",
       "6   can i spend the night        can i order here    \n",
       "7    please write it down           please that      \n",
       "8        the water is hot        the water is hot    \n",
       "9    they always complain  theyre always jealous     \n",
       "10          lock the door         close the door     \n",
       "11              its great             its great      \n",
       "12          i hope we win          i hope you win    \n",
       "13          i can do more          i can explain     \n",
       "14       anyone can do it         anybody can do     "
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "KSq8Ad_NkW7w",
    "outputId": "e6722db0-2751-4902-877b-b833d72c26f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>tom is doing that</td>\n",
       "      <td>tom does that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>follow behind me</td>\n",
       "      <td>help me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>ill take tom home</td>\n",
       "      <td>i going tom home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>are you on facebook</td>\n",
       "      <td>are you on facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>is your family ok</td>\n",
       "      <td>is your mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>we never help tom</td>\n",
       "      <td>we never ask tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>is someone there</td>\n",
       "      <td>is anybody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>are we done</td>\n",
       "      <td>are we done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>tom is quite stupid</td>\n",
       "      <td>tom is quite stupid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>that isnt fair</td>\n",
       "      <td>this not fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>the stamp came off</td>\n",
       "      <td>the noise was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>the crow flew away</td>\n",
       "      <td>the milk is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>im avoiding tom</td>\n",
       "      <td>i envy tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>i never even saw you</td>\n",
       "      <td>i didnt seen see you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>tom wants respect</td>\n",
       "      <td>tom knows them</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    actual                predicted\n",
       "9985     tom is doing that       tom does that     \n",
       "9986      follow behind me            help me      \n",
       "9987     ill take tom home     i going tom home    \n",
       "9988   are you on facebook  are you on facebook    \n",
       "9989     is your family ok         is your mom     \n",
       "9990     we never help tom     we never ask tom    \n",
       "9991      is someone there         is anybody      \n",
       "9992           are we done         are we done     \n",
       "9993   tom is quite stupid  tom is quite stupid    \n",
       "9994        that isnt fair       this not fair     \n",
       "9995    the stamp came off       the noise was     \n",
       "9996    the crow flew away         the milk is     \n",
       "9997       im avoiding tom          i envy tom     \n",
       "9998  i never even saw you  i didnt seen see you   \n",
       "9999     tom wants respect      tom knows them     "
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "azQ9aYyikW72",
    "outputId": "2f29d554-63d9-4a9a-ae70-e9f1659a3cca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>tom is doing that</td>\n",
       "      <td>tom does that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>follow behind me</td>\n",
       "      <td>help me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>ill take tom home</td>\n",
       "      <td>i going tom home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>are you on facebook</td>\n",
       "      <td>are you on facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>is your family ok</td>\n",
       "      <td>is your mom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>we never help tom</td>\n",
       "      <td>we never ask tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>is someone there</td>\n",
       "      <td>is anybody</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>are we done</td>\n",
       "      <td>are we done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>tom is quite stupid</td>\n",
       "      <td>tom is quite stupid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>that isnt fair</td>\n",
       "      <td>this not fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>the stamp came off</td>\n",
       "      <td>the noise was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>the crow flew away</td>\n",
       "      <td>the milk is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>im avoiding tom</td>\n",
       "      <td>i envy tom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>i never even saw you</td>\n",
       "      <td>i didnt seen see you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>tom wants respect</td>\n",
       "      <td>tom knows them</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    actual                predicted\n",
       "9985     tom is doing that       tom does that     \n",
       "9986      follow behind me            help me      \n",
       "9987     ill take tom home     i going tom home    \n",
       "9988   are you on facebook  are you on facebook    \n",
       "9989     is your family ok         is your mom     \n",
       "9990     we never help tom     we never ask tom    \n",
       "9991      is someone there         is anybody      \n",
       "9992           are we done         are we done     \n",
       "9993   tom is quite stupid  tom is quite stupid    \n",
       "9994        that isnt fair       this not fair     \n",
       "9995    the stamp came off       the noise was     \n",
       "9996    the crow flew away         the milk is     \n",
       "9997       im avoiding tom          i envy tom     \n",
       "9998  i never even saw you  i didnt seen see you   \n",
       "9999     tom wants respect      tom knows them     "
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "colab_type": "code",
    "id": "3Hv8fYi9kW78",
    "outputId": "7478afcb-6dde-41a0-e3a9-61e401fb1246"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6664</th>\n",
       "      <td>thats how it is</td>\n",
       "      <td>its just it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8505</th>\n",
       "      <td>were leaving now</td>\n",
       "      <td>well going now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>are you short</td>\n",
       "      <td>are in a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9783</th>\n",
       "      <td>were on your side</td>\n",
       "      <td>were on your side</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>were illiterate</td>\n",
       "      <td>we are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>tom was naive</td>\n",
       "      <td>tom was naive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4097</th>\n",
       "      <td>exercise every day</td>\n",
       "      <td>shes i day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2447</th>\n",
       "      <td>it will be dark soon</td>\n",
       "      <td>itll soon be dark</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>it worked for tom</td>\n",
       "      <td>it looks home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>where did i put it</td>\n",
       "      <td>where did i put it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>i have a truck</td>\n",
       "      <td>i have a website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1872</th>\n",
       "      <td>is it really possible</td>\n",
       "      <td>can he be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>do you have the keys</td>\n",
       "      <td>are you have the keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9366</th>\n",
       "      <td>he must be homesick</td>\n",
       "      <td>hes hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8608</th>\n",
       "      <td>i almost forgot</td>\n",
       "      <td>i paid  it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     actual                 predicted\n",
       "6664        thats how it is          its just it     \n",
       "8505       were leaving now       well going now     \n",
       "2617          are you short             are in a     \n",
       "9783      were on your side     were on your side    \n",
       "2987        were illiterate              we are      \n",
       "2003          tom was naive        tom was naive     \n",
       "4097     exercise every day           shes i day     \n",
       "2447   it will be dark soon     itll soon be dark    \n",
       "3542      it worked for tom        it looks home     \n",
       "5311     where did i put it     where did i put it   \n",
       "565          i have a truck      i have a website    \n",
       "1872  is it really possible            can he be     \n",
       "489    do you have the keys  are you have the keys   \n",
       "9366    he must be homesick            hes hard      \n",
       "8608        i almost forgot            i paid  it    "
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o2RGOR-EkW8C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "german_to_english.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
